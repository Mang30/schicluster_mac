#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¥è§¦è¡°å‡ç‰¹å¾UMAPåˆ†æè„šæœ¬

åŠŸèƒ½ï¼š
1. å°†é•¿æ ¼å¼çš„è¡°å‡æ›²çº¿æ•°æ®è½¬æ¢ä¸ºç»†èƒÃ—ç‰¹å¾çŸ©é˜µ
2. è¿›è¡Œç‰¹å¾é¢„å¤„ç†å’Œé™ç»´
3. ç”ŸæˆUMAPå¯è§†åŒ–å›¾è¡¨
4. ä¿å­˜å¯ç”¨äºä¸‹æ¸¸åˆ†æçš„ç‰¹å¾çŸ©é˜µ

ä½œè€…ï¼šClaude Code Assistant  
æ—¥æœŸï¼š2025-08-29
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging
import warnings
warnings.filterwarnings('ignore')

try:
    import umap
    from sklearn.preprocessing import StandardScaler, RobustScaler
    from sklearn.decomposition import PCA
    from sklearn.manifold import TSNE
except ImportError as e:
    print(f"é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„åŒ…: {e}")
    print("è¯·å®‰è£…ï¼špip install umap-learn scikit-learn")
    sys.exit(1)

# é…ç½®matplotlibä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class ContactDecayUMAPAnalyzer:
    """æ¥è§¦è¡°å‡ç‰¹å¾UMAPåˆ†æå™¨"""
    
    def __init__(self, data_file: str, output_dir: str):
        """
        åˆå§‹åŒ–UMAPåˆ†æå™¨
        
        Args:
            data_file: é•¿æ ¼å¼çš„è¡°å‡æ›²çº¿æ•°æ®æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
        """
        self.data_file = Path(data_file)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # æ•°æ®å­˜å‚¨
        self.raw_data = None
        self.feature_matrix = None
        self.cell_metadata = None
        self.umap_embedding = None
        self.pca_embedding = None
        
    def load_decay_data(self) -> bool:
        """åŠ è½½è¡°å‡æ›²çº¿æ•°æ®"""
        try:
            if not self.data_file.exists():
                raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.data_file}")
            
            self.logger.info(f"åŠ è½½æ•°æ®: {self.data_file}")
            self.raw_data = pd.read_csv(self.data_file)
            
            self.logger.info(f"æ•°æ®å½¢çŠ¶: {self.raw_data.shape}")
            self.logger.info(f"å‘ç°ç»†èƒæ•°: {self.raw_data.groupby(['stage', 'sample']).ngroups}")
            self.logger.info(f"å‘ç°å‘è‚²é˜¶æ®µ: {sorted(self.raw_data['stage'].unique())}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return False
    
    def create_feature_matrix(self, distance_range: Optional[Tuple[float, float]] = None,
                             log_transform: bool = True, 
                             feature_selection: str = 'all') -> bool:
        """
        åˆ›å»ºç»†èƒÃ—ç‰¹å¾çŸ©é˜µ
        
        Args:
            distance_range: è·ç¦»èŒƒå›´è¿‡æ»¤ (min_kb, max_kb)
            log_transform: æ˜¯å¦ä½¿ç”¨å¯¹æ•°å˜æ¢çš„æ¥è§¦é¢‘ç‡
            feature_selection: ç‰¹å¾é€‰æ‹©ç­–ç•¥ ('all', 'uniform', 'log_uniform')
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ›å»º
        """
        try:
            if self.raw_data is None:
                raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®")
            
            self.logger.info("åˆ›å»ºç»†èƒÃ—ç‰¹å¾çŸ©é˜µ...")
            
            # æ•°æ®é¢„å¤„ç†
            data = self.raw_data.copy()
            
            # è·ç¦»èŒƒå›´è¿‡æ»¤
            if distance_range:
                min_kb, max_kb = distance_range
                data = data[
                    (data['distance_kb'] >= min_kb) & 
                    (data['distance_kb'] <= max_kb)
                ]
                self.logger.info(f"è·ç¦»è¿‡æ»¤: {min_kb}-{max_kb} kb, å‰©ä½™æ•°æ®: {len(data)}")
            
            # é€‰æ‹©æ¥è§¦é¢‘ç‡ç‰¹å¾
            if log_transform:
                # ä½¿ç”¨å¯¹æ•°å˜æ¢çš„æ¥è§¦é¢‘ç‡ï¼Œå¤„ç†æ— ç©·å¤§å€¼
                data['feature_value'] = np.log10(data['contact_frequency'] + 1e-10)
                data['feature_value'] = np.nan_to_num(data['feature_value'], 
                                                     nan=0.0, posinf=0.0, neginf=-10.0)
                self.logger.info("ä½¿ç”¨å¯¹æ•°å˜æ¢çš„æ¥è§¦é¢‘ç‡")
            else:
                data['feature_value'] = data['contact_frequency']
                self.logger.info("ä½¿ç”¨åŸå§‹æ¥è§¦é¢‘ç‡")
            
            # ç‰¹å¾é€‰æ‹©
            if feature_selection == 'uniform':
                # å‡åŒ€é‡‡æ ·è·ç¦»ç‚¹
                unique_distances = sorted(data['distance_kb'].unique())
                n_features = min(200, len(unique_distances))  # æœ€å¤š200ä¸ªç‰¹å¾
                selected_distances = unique_distances[::len(unique_distances)//n_features]
                data = data[data['distance_kb'].isin(selected_distances)]
                self.logger.info(f"å‡åŒ€é‡‡æ ·: é€‰æ‹©äº† {len(selected_distances)} ä¸ªè·ç¦»ç‚¹")
                
            elif feature_selection == 'log_uniform':
                # å¯¹æ•°å‡åŒ€é‡‡æ ·
                unique_distances = sorted(data['distance_kb'].unique())
                log_distances = np.log10(unique_distances)
                n_features = min(200, len(unique_distances))
                selected_log = np.linspace(log_distances[0], log_distances[-1], n_features)
                
                # æ‰¾åˆ°æœ€æ¥è¿‘çš„å®é™…è·ç¦»
                selected_distances = []
                for target_log in selected_log:
                    target_dist = 10**target_log
                    closest_dist = min(unique_distances, key=lambda x: abs(x - target_dist))
                    if closest_dist not in selected_distances:
                        selected_distances.append(closest_dist)
                
                data = data[data['distance_kb'].isin(selected_distances)]
                self.logger.info(f"å¯¹æ•°å‡åŒ€é‡‡æ ·: é€‰æ‹©äº† {len(selected_distances)} ä¸ªè·ç¦»ç‚¹")
            
            # åˆ›å»ºé€è§†è¡¨ï¼ˆç»†èƒÃ—ç‰¹å¾çŸ©é˜µï¼‰
            pivot_table = data.pivot_table(
                index=['stage', 'sample'],
                columns='distance_kb', 
                values='feature_value',
                aggfunc='first'  # æ¯ä¸ªç»†èƒæ¯ä¸ªè·ç¦»åªæœ‰ä¸€ä¸ªå€¼
            )
            
            # å¤„ç†ç¼ºå¤±å€¼
            pivot_table = pivot_table.fillna(0)
            
            # æå–ç‰¹å¾çŸ©é˜µå’Œå…ƒæ•°æ®
            self.feature_matrix = pivot_table.values
            self.cell_metadata = pd.DataFrame({
                'stage': [idx[0] for idx in pivot_table.index],
                'sample': [idx[1] for idx in pivot_table.index],
                'cell_id': [f"{idx[0]}_{idx[1]}" for idx in pivot_table.index]
            })
            
            self.logger.info(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {self.feature_matrix.shape}")
            self.logger.info(f"ç»†èƒæ•°é‡: {len(self.cell_metadata)}")
            self.logger.info(f"ç‰¹å¾ç»´åº¦: {self.feature_matrix.shape[1]}")
            
            # ä¿å­˜ç‰¹å¾çŸ©é˜µ
            feature_df = pd.DataFrame(
                self.feature_matrix, 
                columns=[f"distance_{int(col)}kb" for col in pivot_table.columns],
                index=self.cell_metadata['cell_id']
            )
            feature_df = pd.concat([self.cell_metadata.set_index('cell_id'), feature_df], axis=1)
            
            output_file = self.output_dir / 'cell_feature_matrix.csv'
            feature_df.to_csv(output_file)
            self.logger.info(f"ç‰¹å¾çŸ©é˜µå·²ä¿å­˜: {output_file}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºç‰¹å¾çŸ©é˜µå¤±è´¥: {e}")
            return False
    
    def perform_dimensionality_reduction(self, method: str = 'umap', 
                                       n_components: int = 2,
                                       preprocessing: str = 'standard') -> bool:
        """
        è¿›è¡Œé™ç»´åˆ†æ
        
        Args:
            method: é™ç»´æ–¹æ³• ('umap', 'pca', 'tsne')
            n_components: é™ç»´åçš„ç»´åº¦
            preprocessing: é¢„å¤„ç†æ–¹æ³• ('standard', 'robust', 'none')
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            if self.feature_matrix is None:
                raise ValueError("è¯·å…ˆåˆ›å»ºç‰¹å¾çŸ©é˜µ")
            
            self.logger.info(f"å¼€å§‹é™ç»´åˆ†æ: {method}")
            
            # æ•°æ®é¢„å¤„ç†
            if preprocessing == 'standard':
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(self.feature_matrix)
                self.logger.info("ä½¿ç”¨æ ‡å‡†åŒ–é¢„å¤„ç†")
            elif preprocessing == 'robust':
                scaler = RobustScaler()
                X_scaled = scaler.fit_transform(self.feature_matrix)
                self.logger.info("ä½¿ç”¨é²æ£’æ ‡å‡†åŒ–é¢„å¤„ç†")
            else:
                X_scaled = self.feature_matrix
                self.logger.info("ä¸è¿›è¡Œé¢„å¤„ç†")
            
            # é™ç»´
            if method.lower() == 'umap':
                reducer = umap.UMAP(
                    n_components=n_components,
                    n_neighbors=15,
                    min_dist=0.1,
                    metric='euclidean',
                    random_state=42
                )
                embedding = reducer.fit_transform(X_scaled)
                self.umap_embedding = embedding
                self.logger.info(f"UMAPé™ç»´å®Œæˆ: {self.feature_matrix.shape} -> {embedding.shape}")
                
            elif method.lower() == 'pca':
                reducer = PCA(n_components=n_components, random_state=42)
                embedding = reducer.fit_transform(X_scaled)
                self.pca_embedding = embedding
                
                # ä¿å­˜è§£é‡Šæ–¹å·®æ¯”ä¾‹
                explained_var = reducer.explained_variance_ratio_
                self.logger.info(f"PCAé™ç»´å®Œæˆ: å‰{n_components}ä¸ªä¸»æˆåˆ†è§£é‡Šäº† {explained_var.sum():.3f} çš„æ–¹å·®")
                
            elif method.lower() == 'tsne':
                if X_scaled.shape[1] > 50:  # t-SNEå¯¹é«˜ç»´æ•°æ®å…ˆè¿›è¡ŒPCAé¢„å¤„ç†
                    pca = PCA(n_components=50, random_state=42)
                    X_scaled = pca.fit_transform(X_scaled)
                    self.logger.info("t-SNEå‰è¿›è¡ŒPCAé¢„å¤„ç†è‡³50ç»´")
                
                reducer = TSNE(n_components=n_components, random_state=42, 
                             perplexity=min(30, len(X_scaled)//4))
                embedding = reducer.fit_transform(X_scaled)
                self.logger.info(f"t-SNEé™ç»´å®Œæˆ")
            
            # ä¿å­˜é™ç»´ç»“æœ
            embedding_df = pd.DataFrame(
                embedding,
                columns=[f'{method.upper()}{i+1}' for i in range(n_components)],
                index=self.cell_metadata['cell_id']
            )
            embedding_df = pd.concat([self.cell_metadata.set_index('cell_id'), embedding_df], axis=1)
            
            output_file = self.output_dir / f'{method}_embedding.csv'
            embedding_df.to_csv(output_file)
            self.logger.info(f"é™ç»´ç»“æœå·²ä¿å­˜: {output_file}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"é™ç»´åˆ†æå¤±è´¥: {e}")
            return False
    
    def create_umap_plots(self, color_by: str = 'stage', save_plots: bool = True) -> List[str]:
        """
        åˆ›å»ºUMAPå¯è§†åŒ–å›¾è¡¨
        
        Args:
            color_by: ç€è‰²ä¾æ® ('stage', 'sample')
            save_plots: æ˜¯å¦ä¿å­˜å›¾è¡¨
            
        Returns:
            List[str]: ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶è·¯å¾„
        """
        try:
            if self.umap_embedding is None:
                raise ValueError("è¯·å…ˆè¿›è¡ŒUMAPé™ç»´")
            
            plot_files = []
            
            # å‡†å¤‡æ•°æ®
            plot_data = pd.DataFrame({
                'UMAP1': self.umap_embedding[:, 0],
                'UMAP2': self.umap_embedding[:, 1],
                'stage': self.cell_metadata['stage'],
                'sample': self.cell_metadata['sample'],
                'cell_id': self.cell_metadata['cell_id']
            })
            
            # è®¾ç½®é¢œè‰²æ–¹æ¡ˆ
            if color_by == 'stage':
                unique_stages = sorted(plot_data['stage'].unique())
                colors = plt.cm.Set3(np.linspace(0, 1, len(unique_stages)))
                color_map = dict(zip(unique_stages, colors))
                
            # 1. åŸºæœ¬UMAPå›¾
            fig, ax = plt.subplots(figsize=(10, 8))
            
            for stage in sorted(plot_data['stage'].unique()):
                stage_data = plot_data[plot_data['stage'] == stage]
                ax.scatter(stage_data['UMAP1'], stage_data['UMAP2'],
                          c=[color_map[stage]], label=f'é˜¶æ®µ {stage}',
                          alpha=0.7, s=50)
            
            ax.set_xlabel('UMAP1', fontsize=12)
            ax.set_ylabel('UMAP2', fontsize=12)
            ax.set_title('Hi-Cæ¥è§¦è¡°å‡ç‰¹å¾ UMAP åˆ†æ', fontsize=14)
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            if save_plots:
                plot_file = self.output_dir / 'umap_by_stage.png'
                plt.savefig(plot_file, dpi=300, bbox_inches='tight')
                plot_files.append(str(plot_file))
                
            plt.show()
            
            # 2. å¯†åº¦å›¾
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            
            # æ•´ä½“å¯†åº¦
            axes[0,0].hexbin(plot_data['UMAP1'], plot_data['UMAP2'], gridsize=30, cmap='Blues')
            axes[0,0].set_title('ç»†èƒåˆ†å¸ƒå¯†åº¦')
            axes[0,0].set_xlabel('UMAP1')
            axes[0,0].set_ylabel('UMAP2')
            
            # å„é˜¶æ®µåˆ†å¸ƒ
            for i, stage in enumerate(sorted(plot_data['stage'].unique())[:3]):
                ax = axes[0,1] if i == 0 else axes[1, i-1]
                stage_data = plot_data[plot_data['stage'] == stage]
                ax.scatter(stage_data['UMAP1'], stage_data['UMAP2'],
                          c=color_map[stage], alpha=0.6, s=30)
                ax.set_title(f'é˜¶æ®µ {stage}')
                ax.set_xlabel('UMAP1')
                ax.set_ylabel('UMAP2')
                ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            if save_plots:
                plot_file = self.output_dir / 'umap_density_analysis.png'
                plt.savefig(plot_file, dpi=300, bbox_inches='tight')
                plot_files.append(str(plot_file))
                
            plt.show()
            
            # 3. ç»Ÿè®¡æ‘˜è¦
            stage_stats = plot_data.groupby('stage').agg({
                'UMAP1': ['mean', 'std'],
                'UMAP2': ['mean', 'std']
            }).round(3)
            
            print("\nğŸ“Š å„å‘è‚²é˜¶æ®µUMAPåæ ‡ç»Ÿè®¡:")
            print(stage_stats)
            
            # ä¿å­˜ç»Ÿè®¡ç»“æœ
            stats_file = self.output_dir / 'umap_statistics.csv' 
            stage_stats.to_csv(stats_file)
            
            self.logger.info(f"ç”Ÿæˆäº† {len(plot_files)} ä¸ªUMAPå›¾è¡¨")
            return plot_files
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºUMAPå›¾è¡¨å¤±è´¥: {e}")
            return []
    
    def run_complete_analysis(self, distance_range: Tuple[float, float] = (100, 10000),
                            feature_selection: str = 'log_uniform') -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„UMAPåˆ†ææµç¨‹
        
        Args:
            distance_range: åˆ†æçš„è·ç¦»èŒƒå›´ (kb)
            feature_selection: ç‰¹å¾é€‰æ‹©ç­–ç•¥
            
        Returns:
            Dict: åˆ†æç»“æœæ‘˜è¦
        """
        try:
            self.logger.info("å¼€å§‹å®Œæ•´UMAPåˆ†ææµç¨‹...")
            
            # 1. åŠ è½½æ•°æ®
            if not self.load_decay_data():
                return {'success': False, 'error': 'æ•°æ®åŠ è½½å¤±è´¥'}
            
            # 2. åˆ›å»ºç‰¹å¾çŸ©é˜µ
            if not self.create_feature_matrix(
                distance_range=distance_range,
                log_transform=True,
                feature_selection=feature_selection
            ):
                return {'success': False, 'error': 'ç‰¹å¾çŸ©é˜µåˆ›å»ºå¤±è´¥'}
            
            # 3. æ‰§è¡ŒUMAPé™ç»´
            if not self.perform_dimensionality_reduction(method='umap'):
                return {'success': False, 'error': 'UMAPé™ç»´å¤±è´¥'}
            
            # 4. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
            plot_files = self.create_umap_plots()
            
            # 5. è¿”å›ç»“æœæ‘˜è¦
            result_summary = {
                'success': True,
                'n_cells': len(self.cell_metadata),
                'n_features': self.feature_matrix.shape[1],
                'distance_range': distance_range,
                'feature_selection': feature_selection,
                'stages': sorted(self.cell_metadata['stage'].unique()),
                'output_dir': str(self.output_dir),
                'plot_files': plot_files
            }
            
            self.logger.info("UMAPåˆ†ææµç¨‹å®Œæˆ!")
            return result_summary
            
        except Exception as e:
            self.logger.error(f"å®Œæ•´åˆ†æå¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¥è§¦è¡°å‡ç‰¹å¾UMAPåˆ†æå·¥å…·')
    parser.add_argument('-i', '--input', required=True, 
                       help='è¾“å…¥çš„è¡°å‡æ›²çº¿æ•°æ®æ–‡ä»¶ (all_stages_decay_profiles.csv)')
    parser.add_argument('-o', '--output', required=True, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--min-distance', type=float, default=100,
                       help='æœ€å°åˆ†æè·ç¦» (kb)')
    parser.add_argument('--max-distance', type=float, default=10000,
                       help='æœ€å¤§åˆ†æè·ç¦» (kb)')
    parser.add_argument('--feature-selection', choices=['all', 'uniform', 'log_uniform'],
                       default='log_uniform', help='ç‰¹å¾é€‰æ‹©ç­–ç•¥')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = ContactDecayUMAPAnalyzer(
        data_file=args.input,
        output_dir=args.output
    )
    
    # è¿è¡Œåˆ†æ
    results = analyzer.run_complete_analysis(
        distance_range=(args.min_distance, args.max_distance),
        feature_selection=args.feature_selection
    )
    
    # è¾“å‡ºç»“æœ
    if results['success']:
        print(f"\nğŸ‰ UMAPåˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š ç»†èƒæ•°é‡: {results['n_cells']}")
        print(f"ğŸ” ç‰¹å¾ç»´åº¦: {results['n_features']}")  
        print(f"ğŸ§¬ å‘è‚²é˜¶æ®µ: {results['stages']}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {results['output_dir']}")
        print(f"ğŸ“ˆ ç”Ÿæˆå›¾è¡¨: {len(results['plot_files'])} ä¸ª")
    else:
        print(f"âŒ åˆ†æå¤±è´¥: {results['error']}")
        sys.exit(1)


if __name__ == "__main__":
    main()