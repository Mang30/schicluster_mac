#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ‰¹é‡å¤„ç†å„ä¸ªå‘è‚²é˜¶æ®µçš„æ¥è§¦è¡°å‡æ›²çº¿åˆ†æè„šæœ¬

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨å‘ç°å„ä¸ªstageç›®å½•ä¸‹çš„.coolæ–‡ä»¶
2. æ‰¹é‡è¿è¡Œæ¥è§¦è¡°å‡æ›²çº¿åˆ†æ
3. ç”Ÿæˆå¯¹æ¯”åˆ†æç»“æœ
4. å¹¶è¡Œå¤„ç†ä»¥æé«˜æ•ˆç‡

ä½œè€…ï¼šClaude Code Assistant
æ—¥æœŸï¼š2025-08-29
"""

import os
import sys
import json
import logging
import argparse
from pathlib import Path
from typing import Dict, List, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

try:
    from contact_decay_analyzer import ContactDecayAnalyzer
except ImportError:
    print("é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ContactDecayAnalyzerï¼Œè¯·æ£€æŸ¥srcç›®å½•")
    sys.exit(1)

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class StageWiseDecayProcessor:
    """å‘è‚²é˜¶æ®µæ¥è§¦è¡°å‡æ‰¹é‡å¤„ç†å™¨"""
    
    def __init__(self, data_root_dir: str, output_dir: str, 
                 stages: Optional[List[str]] = None):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            data_root_dir: æ•°æ®æ ¹ç›®å½•è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            stages: è¦å¤„ç†çš„å‘è‚²é˜¶æ®µåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰å‘ç°çš„é˜¶æ®µ
        """
        self.data_root_dir = Path(data_root_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # å‘è‚²é˜¶æ®µ
        self.stages = stages if stages else self._discover_stages()
        self.logger.info(f"å‘ç°çš„å‘è‚²é˜¶æ®µ: {self.stages}")
        
        # ç»“æœå­˜å‚¨
        self.stage_results = {}
        self.all_decay_profiles = {}
        
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = self.output_dir / f"batch_processing_{timestamp}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def _discover_stages(self) -> List[str]:
        """è‡ªåŠ¨å‘ç°æ•°æ®ç›®å½•ä¸­çš„å‘è‚²é˜¶æ®µ"""
        stages = []
        
        try:
            # æŸ¥æ‰¾ä»¥Eæˆ–EXå¼€å¤´çš„ç›®å½•
            for item in self.data_root_dir.iterdir():
                if item.is_dir() and (item.name.startswith('E') or item.name.startswith('EX')):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ’è¡¥æ•°æ®
                    impute_dir = item / 'impute' / '100K' / 'chunk0'
                    if impute_dir.exists() and any(impute_dir.glob('*.cool')):
                        stages.append(item.name)
                        
            # æŒ‰åç§°æ’åº
            stages.sort(key=lambda x: (len(x), x))
            return stages
            
        except Exception as e:
            self.logger.error(f"å‘ç°å‘è‚²é˜¶æ®µå¤±è´¥: {e}")
            return []
    
    def _get_stage_cool_files(self, stage: str, max_files: Optional[int] = None) -> List[Path]:
        """
        è·å–æŒ‡å®šé˜¶æ®µçš„.coolæ–‡ä»¶åˆ—è¡¨
        
        Args:
            stage: å‘è‚²é˜¶æ®µåç§°
            max_files: æœ€å¤§æ–‡ä»¶æ•°é‡é™åˆ¶
            
        Returns:
            List[Path]: .coolæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        cool_files = []
        
        try:
            stage_dir = self.data_root_dir / stage / 'impute' / '100K' / 'chunk0'
            if not stage_dir.exists():
                self.logger.warning(f"é˜¶æ®µ {stage} çš„æ•°æ®ç›®å½•ä¸å­˜åœ¨: {stage_dir}")
                return []
            
            # æŸ¥æ‰¾æ‰€æœ‰.coolæ–‡ä»¶
            cool_files = list(stage_dir.glob('*.cool'))
            
            # é™åˆ¶æ–‡ä»¶æ•°é‡
            if max_files and len(cool_files) > max_files:
                cool_files = cool_files[:max_files]
                self.logger.info(f"é˜¶æ®µ {stage}: é™åˆ¶å¤„ç†æ–‡ä»¶æ•°é‡ä¸º {max_files}")
            
            self.logger.info(f"é˜¶æ®µ {stage}: å‘ç° {len(cool_files)} ä¸ª.coolæ–‡ä»¶")
            return cool_files
            
        except Exception as e:
            self.logger.error(f"è·å–é˜¶æ®µ {stage} çš„æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def process_single_file(self, cool_file: Path, stage: str, 
                           output_subdir: str, **kwargs) -> Dict:
        """
        å¤„ç†å•ä¸ª.coolæ–‡ä»¶
        
        Args:
            cool_file: .coolæ–‡ä»¶è·¯å¾„
            stage: å‘è‚²é˜¶æ®µ
            output_subdir: è¾“å‡ºå­ç›®å½•
            **kwargs: ä¼ é€’ç»™åˆ†æå™¨çš„å‚æ•°
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            file_output_dir = self.output_dir / output_subdir / cool_file.stem
            
            # åˆ›å»ºåˆ†æå™¨
            analyzer = ContactDecayAnalyzer(
                cool_path=str(cool_file),
                output_dir=str(file_output_dir),
                log_level='WARNING'  # å‡å°‘å¹¶è¡Œå¤„ç†æ—¶çš„æ—¥å¿—è¾“å‡º
            )
            
            # è¿è¡Œåˆ†æ
            results = analyzer.run_complete_analysis(
                chrom=kwargs.get('chrom'),
                max_distance=kwargs.get('max_distance'),
                save_plots=kwargs.get('save_plots', True),
                show_plots=False
            )
            
            # æ·»åŠ é˜¶æ®µä¿¡æ¯
            results['stage'] = stage
            results['cool_file'] = str(cool_file)
            
            return results
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'stage': stage,
                'cool_file': str(cool_file)
            }
    
    def process_stage(self, stage: str, max_files: Optional[int] = None, 
                     parallel: bool = True, max_workers: int = 4, **kwargs) -> Dict:
        """
        å¤„ç†å•ä¸ªå‘è‚²é˜¶æ®µçš„æ‰€æœ‰.coolæ–‡ä»¶
        
        Args:
            stage: å‘è‚²é˜¶æ®µåç§°
            max_files: æœ€å¤§å¤„ç†æ–‡ä»¶æ•°é‡
            parallel: æ˜¯å¦ä½¿ç”¨å¹¶è¡Œå¤„ç†
            max_workers: å¹¶è¡Œå¤„ç†çš„æœ€å¤§workeræ•°é‡
            **kwargs: ä¼ é€’ç»™åˆ†æçš„å‚æ•°
            
        Returns:
            Dict: é˜¶æ®µå¤„ç†ç»“æœæ‘˜è¦
        """
        self.logger.info(f"å¼€å§‹å¤„ç†å‘è‚²é˜¶æ®µ: {stage}")
        
        # è·å–æ–‡ä»¶åˆ—è¡¨
        cool_files = self._get_stage_cool_files(stage, max_files)
        if not cool_files:
            return {'stage': stage, 'success': False, 'error': 'æœªæ‰¾åˆ°.coolæ–‡ä»¶'}
        
        # åˆ›å»ºé˜¶æ®µè¾“å‡ºç›®å½•
        stage_output_dir = f"stage_{stage}"
        
        # å¤„ç†æ–‡ä»¶
        results = []
        successful_count = 0
        failed_count = 0
        
        if parallel and len(cool_files) > 1:
            # å¹¶è¡Œå¤„ç†
            with ProcessPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤ä»»åŠ¡
                future_to_file = {
                    executor.submit(
                        self.process_single_file, 
                        cool_file, stage, stage_output_dir, **kwargs
                    ): cool_file 
                    for cool_file in cool_files
                }
                
                # æ”¶é›†ç»“æœ
                for future in as_completed(future_to_file):
                    cool_file = future_to_file[future]
                    try:
                        result = future.result()
                        results.append(result)
                        
                        if result.get('success', False):
                            successful_count += 1
                            self.logger.info(f"âœ… {cool_file.stem}: å¤„ç†æˆåŠŸ")
                        else:
                            failed_count += 1
                            self.logger.error(f"âŒ {cool_file.stem}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                            
                    except Exception as e:
                        failed_count += 1
                        self.logger.error(f"âŒ {cool_file.stem}: æ‰§è¡Œå¼‚å¸¸ - {e}")
                        results.append({
                            'success': False,
                            'error': str(e),
                            'stage': stage,
                            'cool_file': str(cool_file)
                        })
        else:
            # ä¸²è¡Œå¤„ç†
            for cool_file in cool_files:
                result = self.process_single_file(cool_file, stage, stage_output_dir, **kwargs)
                results.append(result)
                
                if result.get('success', False):
                    successful_count += 1
                    self.logger.info(f"âœ… {cool_file.stem}: å¤„ç†æˆåŠŸ")
                else:
                    failed_count += 1
                    self.logger.error(f"âŒ {cool_file.stem}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # æ±‡æ€»ç»“æœ
        stage_summary = {
            'stage': stage,
            'total_files': len(cool_files),
            'successful': successful_count,
            'failed': failed_count,
            'success_rate': successful_count / len(cool_files) if cool_files else 0,
            'results': results,
            'output_dir': str(self.output_dir / stage_output_dir)
        }
        
        # ä¿å­˜é˜¶æ®µæ‘˜è¦
        summary_file = self.output_dir / f"stage_{stage}_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(stage_summary, f, indent=2, ensure_ascii=False, default=str)
        
        self.logger.info(f"é˜¶æ®µ {stage} å¤„ç†å®Œæˆ: {successful_count}/{len(cool_files)} æˆåŠŸ")
        return stage_summary
    
    def collect_decay_profiles(self) -> pd.DataFrame:
        """æ”¶é›†æ‰€æœ‰æˆåŠŸåˆ†æçš„è¡°å‡æ›²çº¿æ•°æ®"""
        all_profiles = []
        
        for stage in self.stages:
            stage_dir = self.output_dir / f"stage_{stage}"
            if not stage_dir.exists():
                continue
                
            # æŸ¥æ‰¾æ‰€æœ‰è¡°å‡æ›²çº¿æ–‡ä»¶
            for profile_file in stage_dir.glob('*/*/decay_profile.csv'):
                try:
                    df = pd.read_csv(profile_file)
                    df['stage'] = stage
                    df['sample'] = profile_file.parent.name
                    all_profiles.append(df)
                except Exception as e:
                    self.logger.warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {profile_file}: {e}")
        
        if all_profiles:
            combined_df = pd.concat(all_profiles, ignore_index=True)
            
            # ä¿å­˜åˆå¹¶çš„æ•°æ®
            output_file = self.output_dir / 'all_stages_decay_profiles.csv'
            combined_df.to_csv(output_file, index=False)
            self.logger.info(f"åˆå¹¶çš„è¡°å‡æ›²çº¿æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
            
            return combined_df
        else:
            self.logger.warning("æœªæ‰¾åˆ°ä»»ä½•è¡°å‡æ›²çº¿æ•°æ®")
            return pd.DataFrame()
    
    def create_comparative_plots(self, combined_df: pd.DataFrame) -> List[str]:
        """åˆ›å»ºå„é˜¶æ®µé—´çš„å¯¹æ¯”å›¾è¡¨"""
        if combined_df.empty:
            return []
        
        plot_files = []
        
        try:
            # è®¾ç½®é¢œè‰²æ–¹æ¡ˆ
            stage_colors = plt.cm.Set3(np.linspace(0, 1, len(self.stages)))
            color_map = dict(zip(self.stages, stage_colors))
            
            # 1. å„é˜¶æ®µå¹³å‡è¡°å‡æ›²çº¿å¯¹æ¯”
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
            
            # è®¡ç®—æ¯ä¸ªé˜¶æ®µçš„å¹³å‡è¡°å‡æ›²çº¿
            for stage in self.stages:
                stage_data = combined_df[combined_df['stage'] == stage]
                if stage_data.empty:
                    continue
                    
                # æŒ‰è·ç¦»åˆ†ç»„è®¡ç®—å¹³å‡å€¼
                avg_decay = stage_data.groupby('distance_kb')['contact_frequency'].mean()
                
                if not avg_decay.empty:
                    # çº¿æ€§å›¾
                    ax1.plot(avg_decay.index, avg_decay.values, 
                            'o-', markersize=3, linewidth=2, 
                            label=f'é˜¶æ®µ {stage}', color=color_map[stage], alpha=0.8)
                    
                    # åŒå¯¹æ•°å›¾
                    ax2.loglog(avg_decay.index, avg_decay.values, 
                              'o-', markersize=3, linewidth=2, 
                              label=f'é˜¶æ®µ {stage}', color=color_map[stage], alpha=0.8)
            
            # è®¾ç½®å›¾è¡¨
            ax1.set_xlabel('åŸºå› ç»„è·ç¦» (kb)')
            ax1.set_ylabel('å¹³å‡æ¥è§¦é¢‘ç‡')
            ax1.set_title('å„å‘è‚²é˜¶æ®µæ¥è§¦è¡°å‡å¯¹æ¯” (çº¿æ€§åæ ‡)')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            ax2.set_xlabel('åŸºå› ç»„è·ç¦» (kb)')
            ax2.set_ylabel('å¹³å‡æ¥è§¦é¢‘ç‡')
            ax2.set_title('å„å‘è‚²é˜¶æ®µæ¥è§¦è¡°å‡å¯¹æ¯” (åŒå¯¹æ•°åæ ‡)')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            plot_file = self.output_dir / 'stage_comparison_decay_curves.png'
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plot_files.append(str(plot_file))
            plt.close()
            
            # 2. çƒ­å›¾å±•ç¤ºä¸åŒè·ç¦»ä¸‹å„é˜¶æ®µçš„æ¥è§¦å¼ºåº¦
            if len(self.stages) > 1:
                # å‡†å¤‡çƒ­å›¾æ•°æ®
                pivot_data = []
                distance_points = sorted(combined_df['distance_kb'].unique())[:20]  # å–å‰20ä¸ªè·ç¦»ç‚¹
                
                for stage in self.stages:
                    stage_data = combined_df[combined_df['stage'] == stage]
                    stage_avg = []
                    
                    for dist in distance_points:
                        dist_data = stage_data[abs(stage_data['distance_kb'] - dist) < 10]  # å…è®¸ä¸€å®šè¯¯å·®
                        if not dist_data.empty:
                            stage_avg.append(dist_data['contact_frequency'].mean())
                        else:
                            stage_avg.append(np.nan)
                    
                    pivot_data.append(stage_avg)
                
                # åˆ›å»ºçƒ­å›¾
                fig, ax = plt.subplots(figsize=(12, 6))
                heatmap_data = np.array(pivot_data)
                
                # ä½¿ç”¨å¯¹æ•°å˜æ¢
                heatmap_data_log = np.log10(heatmap_data + 1e-10)  # é¿å…log(0)
                
                im = ax.imshow(heatmap_data_log, aspect='auto', cmap='viridis')
                
                # è®¾ç½®æ ‡ç­¾
                ax.set_xticks(range(len(distance_points)))
                ax.set_xticklabels([f'{int(d)}kb' for d in distance_points], rotation=45)
                ax.set_yticks(range(len(self.stages)))
                ax.set_yticklabels(self.stages)
                
                ax.set_xlabel('åŸºå› ç»„è·ç¦»')
                ax.set_ylabel('å‘è‚²é˜¶æ®µ')
                ax.set_title('å„å‘è‚²é˜¶æ®µæ¥è§¦å¼ºåº¦çƒ­å›¾ (log10å˜æ¢)')
                
                # æ·»åŠ é¢œè‰²æ¡
                plt.colorbar(im, ax=ax, label='log10(æ¥è§¦é¢‘ç‡)')
                plt.tight_layout()
                
                # ä¿å­˜å›¾ç‰‡
                heatmap_file = self.output_dir / 'stage_contact_heatmap.png'
                plt.savefig(heatmap_file, dpi=300, bbox_inches='tight')
                plot_files.append(str(heatmap_file))
                plt.close()
            
            self.logger.info(f"ç”Ÿæˆå¯¹æ¯”å›¾è¡¨: {len(plot_files)} ä¸ª")
            return plot_files
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå¯¹æ¯”å›¾è¡¨å¤±è´¥: {e}")
            return []
    
    def run_batch_processing(self, max_files_per_stage: Optional[int] = None,
                           parallel: bool = True, max_workers: int = 4,
                           **analysis_kwargs) -> Dict:
        """
        è¿è¡Œæ‰¹é‡å¤„ç†æµç¨‹
        
        Args:
            max_files_per_stage: æ¯ä¸ªé˜¶æ®µæœ€å¤§å¤„ç†æ–‡ä»¶æ•°
            parallel: æ˜¯å¦ä½¿ç”¨å¹¶è¡Œå¤„ç†
            max_workers: æœ€å¤§workeræ•°é‡
            **analysis_kwargs: ä¼ é€’ç»™åˆ†æçš„å‚æ•°
            
        Returns:
            Dict: æ‰¹é‡å¤„ç†ç»“æœæ‘˜è¦
        """
        start_time = datetime.now()
        self.logger.info("å¼€å§‹æ‰¹é‡å¤„ç†æ‰€æœ‰å‘è‚²é˜¶æ®µ")
        
        # å¤„ç†æ¯ä¸ªé˜¶æ®µ
        all_results = {}
        total_successful = 0
        total_files = 0
        
        for stage in self.stages:
            stage_result = self.process_stage(
                stage=stage,
                max_files=max_files_per_stage,
                parallel=parallel,
                max_workers=max_workers,
                **analysis_kwargs
            )
            
            all_results[stage] = stage_result
            total_successful += stage_result.get('successful', 0)
            total_files += stage_result.get('total_files', 0)
        
        # æ”¶é›†è¡°å‡æ›²çº¿æ•°æ®
        combined_df = self.collect_decay_profiles()
        
        # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
        comparison_plots = []
        if not combined_df.empty:
            comparison_plots = self.create_comparative_plots(combined_df)
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        final_summary = {
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'processing_time_seconds': processing_time,
            'stages_processed': len(self.stages),
            'total_files': total_files,
            'total_successful': total_successful,
            'overall_success_rate': total_successful / total_files if total_files > 0 else 0,
            'stage_results': all_results,
            'output_directory': str(self.output_dir),
            'comparison_plots': comparison_plots,
            'combined_data_points': len(combined_df) if not combined_df.empty else 0
        }
        
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        report_file = self.output_dir / 'batch_processing_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(final_summary, f, indent=2, ensure_ascii=False, default=str)
        
        self.logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆï¼")
        self.logger.info(f"æ€»è€—æ—¶: {processing_time:.1f} ç§’")
        self.logger.info(f"å¤„ç†æ–‡ä»¶: {total_successful}/{total_files} æˆåŠŸ")
        self.logger.info(f"æœ€ç»ˆæŠ¥å‘Š: {report_file}")
        
        return final_summary


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ‰¹é‡å¤„ç†å‘è‚²é˜¶æ®µæ¥è§¦è¡°å‡æ›²çº¿åˆ†æ')
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('-i', '--input', required=True, 
                       help='è¾“å…¥æ•°æ®æ ¹ç›®å½• (åŒ…å«å„ä¸ªstageå­ç›®å½•)')
    parser.add_argument('-o', '--output', required=True, 
                       help='è¾“å‡ºç›®å½•')
    
    # å¯é€‰å‚æ•°
    parser.add_argument('-s', '--stages', nargs='+', 
                       help='æŒ‡å®šè¦å¤„ç†çš„å‘è‚²é˜¶æ®µ (é»˜è®¤å¤„ç†æ‰€æœ‰å‘ç°çš„é˜¶æ®µ)')
    parser.add_argument('-n', '--max-files', type=int, 
                       help='æ¯ä¸ªé˜¶æ®µæœ€å¤§å¤„ç†æ–‡ä»¶æ•°é‡')
    parser.add_argument('-w', '--max-workers', type=int, default=4,
                       help='å¹¶è¡Œå¤„ç†çš„æœ€å¤§workeræ•°é‡')
    parser.add_argument('--no-parallel', action='store_true',
                       help='ç¦ç”¨å¹¶è¡Œå¤„ç†')
    
    # åˆ†æå‚æ•°
    parser.add_argument('-c', '--chrom', help='åˆ†ææŒ‡å®šæŸ“è‰²ä½“')
    parser.add_argument('-d', '--max-distance', type=int, help='æœ€å¤§åˆ†æè·ç¦»')
    parser.add_argument('--no-plots', action='store_true', help='ä¸ç”Ÿæˆå›¾è¡¨')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = StageWiseDecayProcessor(
        data_root_dir=args.input,
        output_dir=args.output,
        stages=args.stages
    )
    
    # è¿è¡Œæ‰¹é‡å¤„ç†
    results = processor.run_batch_processing(
        max_files_per_stage=args.max_files,
        parallel=not args.no_parallel,
        max_workers=args.max_workers,
        chrom=args.chrom,
        max_distance=args.max_distance,
        save_plots=not args.no_plots
    )
    
    # è¾“å‡ºç»“æœæ‘˜è¦
    print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“Š å¤„ç†äº† {results['stages_processed']} ä¸ªå‘è‚²é˜¶æ®µ")
    print(f"ğŸ“ æˆåŠŸåˆ†æ {results['total_successful']}/{results['total_files']} ä¸ªæ–‡ä»¶")
    print(f"â±ï¸  æ€»è€—æ—¶: {results['processing_time_seconds']:.1f} ç§’")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {results['overall_success_rate']*100:.1f}%")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {results['output_directory']}")
    
    if results['comparison_plots']:
        print(f"ğŸ“Š ç”Ÿæˆå¯¹æ¯”å›¾è¡¨: {len(results['comparison_plots'])} ä¸ª")


if __name__ == "__main__":
    main()